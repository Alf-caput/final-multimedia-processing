{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "for frame in video:\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: pretrained_models\\yolo11n.pt\n",
      "Labels(n=80): ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "filename = \"yolo11n.pt\"\n",
    "input_path = os.path.join(models_path, filename)\n",
    "\n",
    "model = YOLO(input_path)\n",
    "labels = list(model.names.values())\n",
    "n = len(labels)\n",
    "\n",
    "print(f\"Model: {input_path}\")\n",
    "print(f\"Labels({n=}): {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO aplicado a imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 106.0ms\n",
      "Speed: 5.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.9402])\n",
      "data: tensor([[  3.8328, 229.3642, 796.1946, 728.4123,   1.0000,   0.9402,   5.0000]])\n",
      "id: tensor([1.])\n",
      "is_track: True\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 7])\n",
      "xywh: tensor([[400.0137, 478.8882, 792.3618, 499.0481]])\n",
      "xywhn: tensor([[0.4938, 0.4434, 0.9782, 0.4621]])\n",
      "xyxy: tensor([[  3.8328, 229.3642, 796.1946, 728.4123]])\n",
      "xyxyn: tensor([[0.0047, 0.2124, 0.9830, 0.6745]])\n",
      "\n",
      "Label(id=5): bus\n",
      "-> Location: x=400.01, y=478.89, w=792.36, h=499.05\n",
      "Label(id=0): person\n",
      "-> Location: x=740.41, y=636.77, w=138.79, h=483.88\n",
      "Label(id=0): person\n",
      "-> Location: x=143.35, y=651.88, w=191.90, h=504.63\n",
      "Label(id=0): person\n",
      "-> Location: x=283.76, y=634.56, w=121.41, h=451.75\n",
      "Label(id=0): person\n",
      "-> Location: x=34.45, y=714.21, w=68.86, h=316.29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "data_path = \"data\"\n",
    "filename = \"bus.jpg\"\n",
    "input_path = os.path.join(data_path, filename)\n",
    "\n",
    "frame = cv2.imread(input_path)\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "results = yolo.track(frame, show=True)\n",
    "\n",
    "obj = results[0].boxes[0]\n",
    "print(obj, end=\"\\n\\n\")\n",
    "\n",
    "for obj in results[0].boxes:\n",
    "    id = obj.cls.item() # .item() extracts value of tensor of a single element\n",
    "    x, y, w, h = obj.xywh[0].numpy() # converting to numpy allows to unpack (readability)\n",
    "    print(f\"Label(id={id:.0f}): {yolo.names[id]}\", end=\"\\n-> \")\n",
    "    print(f\"Location: {x=:.2f}, {y=:.2f}, {w=:.2f}, {h=:.2f}\", end=\"\\n\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO aplicado a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path)\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame, show=True, verbose=False)\n",
    "    if i > 25:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO aplicado a Video en región de interés solo para la detección (imshow customizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], verbose=False, persist=True, classes=[2, 7], conf=0.45, iou=0.5)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "            cv2.putText(frame[roi_mask], f\"{id}\", (x, y-3), 0, 0.5, (0, 0, 255), 1)\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "    \n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seguimiento de posiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n",
      "5: [(115, 47, 0)]\n",
      "2: [(166, 3, 0), (166, 3, 1), (166, 3, 2), (166, 3, 3), (167, 3, 4), (167, 2, 5), (168, 2, 6), (168, 2, 7), (168, 2, 8)]\n",
      "9: [(8, 109, 27)]\n",
      "1: [(183, 20, 0), (183, 20, 1), (183, 20, 2), (183, 19, 3), (183, 18, 4), (184, 18, 5), (184, 17, 6), (184, 17, 7), (184, 16, 8), (184, 15, 9), (185, 15, 10), (185, 14, 11), (185, 14, 12), (185, 13, 13), (185, 13, 14), (185, 12, 15), (185, 12, 16), (185, 12, 17), (185, 11, 18), (185, 10, 19), (185, 10, 20), (186, 9, 22), (186, 8, 23), (186, 8, 24), (187, 7, 25), (187, 6, 27), (187, 6, 28), (187, 6, 29), (187, 6, 30), (187, 6, 31)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "obj_positions = {}\n",
    "detection_lifetime_frames = 5\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            if id not in obj_positions.keys():\n",
    "                obj_positions[id] = [obj_pos_frame]\n",
    "            else:\n",
    "                obj_positions[id].append(obj_pos_frame)\n",
    "\n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "    for id in list(obj_positions.keys()):\n",
    "        if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "            print(f\"{id}: {obj_positions[id]}\")\n",
    "            del obj_positions[id]\n",
    "    \n",
    "    if i == 50: # Early stop\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de pixels por segundo (velocidad instantánea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "obj_positions = {}\n",
    "detection_lifetime_frames = 5\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            if id not in obj_positions.keys():\n",
    "                obj_positions[id] = [obj_pos_frame]\n",
    "            else:\n",
    "                obj_positions[id].append(obj_pos_frame)\n",
    "                xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                cv2.putText(frame[roi_mask], f\"{vy:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "    for id in list(obj_positions.keys()):\n",
    "        if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "            del obj_positions[id]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocidad media en región de interés (para cada objeto entre primera y última detecciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "obj_positions = {}\n",
    "obj_velocities = {}\n",
    "detection_lifetime_frames = 5\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            if id not in obj_positions.keys():\n",
    "                obj_positions[id] = [obj_pos_frame]\n",
    "                obj_velocities[id] = None\n",
    "            else:\n",
    "                obj_positions[id].append(obj_pos_frame)\n",
    "                xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                if obj_velocities[id] is None:\n",
    "                    obj_velocities[id] = vy\n",
    "                else:\n",
    "                    obj_velocities[id] = (obj_velocities[id] + vy) / 2 \n",
    "\n",
    "                cv2.putText(frame[roi_mask], f\"{obj_velocities[id]:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "\n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    if obj_velocities:\n",
    "        filtered = [value for value in obj_velocities.values() if value is not None] # Remove None's\n",
    "        avg_speed = np.mean(filtered)\n",
    "        cv2.putText(frame, f\"Avg speed: {avg_speed:.2f}px/s\", (x1_roi-5, y1_roi-5), 0, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "    for id in list(obj_positions.keys()):\n",
    "        if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "            del obj_positions[id]\n",
    "            del obj_velocities[id]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocidad media total (todos las detecciones) en la región de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "obj_positions = {}\n",
    "obj_velocities = {}\n",
    "detection_lifetime_frames = 5\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            if id not in obj_positions.keys():\n",
    "                obj_positions[id] = [obj_pos_frame]\n",
    "                obj_velocities[id] = None\n",
    "            else:\n",
    "                obj_positions[id].append(obj_pos_frame)\n",
    "                xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                if obj_velocities[id] is None:\n",
    "                    obj_velocities[id] = vy\n",
    "                else:\n",
    "                    obj_velocities[id] = (obj_velocities[id] + vy) / 2 \n",
    "\n",
    "                cv2.putText(frame[roi_mask], f\"{obj_velocities[id]:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "\n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    if obj_velocities:\n",
    "        filtered = [value for value in obj_velocities.values() if value is not None] # Remove None's\n",
    "        if filtered:\n",
    "            avg_speed = np.mean(filtered)\n",
    "            cv2.putText(frame, f\"Avg speed: {avg_speed:.2f}px/s\", (x1_roi-5, y1_roi-5), 0, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "    for id in list(obj_positions.keys()):\n",
    "        if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "            del obj_positions[id]\n",
    "            del obj_velocities[id]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condición existencia de tráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "\n",
    "data_path = \"data\"\n",
    "video_name = \"cars-highway.mp4\"\n",
    "video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "video = Video(video_path)\n",
    "print(f\"{video.name = }\")\n",
    "print(f\"{video.shape = }\")\n",
    "print(f\"{video.fps = }\")\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "model_name = \"yolo11n.pt\"\n",
    "yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "x1_roi, x2_roi = 90, 280\n",
    "y1_roi, y2_roi = 170, 290\n",
    "roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "obj_positions = {}\n",
    "obj_velocities = {}\n",
    "detection_lifetime_frames = 5\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "    for obj in results[0].boxes:\n",
    "        try:\n",
    "            id = int(obj.id.item())\n",
    "            x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "            obj_pos_frame = (x, y, i)\n",
    "\n",
    "            if id not in obj_positions.keys():\n",
    "                obj_positions[id] = [obj_pos_frame]\n",
    "                obj_velocities[id] = None\n",
    "            else:\n",
    "                obj_positions[id].append(obj_pos_frame)\n",
    "                xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                if obj_velocities[id] is None:\n",
    "                    obj_velocities[id] = vy\n",
    "                else:\n",
    "                    obj_velocities[id] = (obj_velocities[id] + vy) / 2 \n",
    "\n",
    "                cv2.putText(frame[roi_mask], f\"{obj_velocities[id]:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "\n",
    "            cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(\"Invalid object, resuming...\")\n",
    "            continue\n",
    "\n",
    "    cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "    vehicle_count = len(results[0].boxes)\n",
    "    cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    if obj_velocities:\n",
    "        filtered = [value for value in obj_velocities.values() if value is not None] # Remove None's\n",
    "        if filtered:\n",
    "            avg_speed = np.mean(filtered)\n",
    "            cv2.putText(frame, f\"Avg speed: {avg_speed:.2f}px/s\", (x1_roi-5, y1_roi-5), 0, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "            bool_traffic = avg_speed < 15 and vehicle_count > 3\n",
    "            cv2.putText(frame, f\"Traffic: {bool_traffic}\", (20, 20), 0, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "    for id in list(obj_positions.keys()):\n",
    "        if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "            del obj_positions[id]\n",
    "            del obj_velocities[id]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "    \n",
    "def main():\n",
    "    data_path = \"data\"\n",
    "    video_name = \"cars-highway.mp4\"\n",
    "    video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "    video = Video(video_path)\n",
    "    print(f\"{video.name = }\")\n",
    "    print(f\"{video.shape = }\")\n",
    "    print(f\"{video.fps = }\")\n",
    "\n",
    "    models_path = \"pretrained_models\"\n",
    "    model_name = \"yolo11n.pt\"\n",
    "    yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "    yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "    x1_roi, x2_roi = 90, 280\n",
    "    y1_roi, y2_roi = 170, 290\n",
    "    roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "    obj_positions = {}\n",
    "    obj_velocities = {}\n",
    "    avg_velocities = {}\n",
    "    detection_lifetime_frames = 5\n",
    "\n",
    "    for i, frame in enumerate(video):\n",
    "        results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "        for obj in results[0].boxes:\n",
    "            try:\n",
    "                id = int(obj.id.item())\n",
    "                x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "                obj_pos_frame = (x, y, i)\n",
    "\n",
    "                if id not in obj_positions.keys():\n",
    "                    obj_positions[id] = [obj_pos_frame]\n",
    "                    obj_velocities[id] = [None]\n",
    "                    avg_velocities[id] = None\n",
    "                else:\n",
    "                    obj_positions[id].append(obj_pos_frame)\n",
    "                    xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                    ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                    frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                    vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                    vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                    if obj_velocities[id] == [None]:\n",
    "                        obj_velocities[id] = [vy]\n",
    "                        avg_velocities[id] = vy\n",
    "                    else:\n",
    "                        obj_velocities[id].append(vy)\n",
    "                        avg_velocities[id] = np.mean(obj_velocities[id])\n",
    "                        cv2.putText(frame[roi_mask], f\"{avg_velocities[id]:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "            \n",
    "\n",
    "                cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "            except AttributeError:\n",
    "                print(\"Invalid object, resuming...\")\n",
    "                continue\n",
    "\n",
    "        cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "        vehicle_count = len(results[0].boxes)\n",
    "        cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        filtered = [value for value in avg_velocities.values() if value is not None] # Remove None's\n",
    "        if filtered:\n",
    "            avg_speed = np.mean(filtered)\n",
    "            bool_traffic = avg_speed < 15 and vehicle_count > 3\n",
    "            cv2.putText(frame, f\"Traffic: {bool_traffic}\", (20, 20), 0, 0.5, (255, 0, 0), 1)\n",
    "            cv2.putText(frame, f\"Avg speed: {avg_speed:.2f}px/s\", (x1_roi-5, y1_roi-5), 0, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow(\"YOLO\", frame)\n",
    "\n",
    "        for id in list(obj_positions.keys()):\n",
    "            if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "                del obj_positions[id]\n",
    "                del obj_velocities[id]\n",
    "                del avg_velocities[id]\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escribir el resultado del procesamiento a un .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video.name = 'cars-highway'\n",
      "video.shape = [640, 360, 51201]\n",
      "video.fps = 25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, video_path):\n",
    "        self.path = video_path\n",
    "        self.name, self.extension = os.path.splitext(os.path.basename(self.path))\n",
    "        self.capture = cv2.VideoCapture(video_path)\n",
    "        self.fps, *self.shape = map(\n",
    "            lambda prop: int(self.capture.get(prop)),\n",
    "            [\n",
    "                cv2.CAP_PROP_FPS,\n",
    "                cv2.CAP_PROP_FRAME_WIDTH,\n",
    "                cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "                cv2.CAP_PROP_FRAME_COUNT,\n",
    "            ]\n",
    "        )\n",
    "        self.capture.release()\n",
    "    \n",
    "    def frame_gen(self):\n",
    "        self.capture = cv2.VideoCapture(self.path)\n",
    "\n",
    "        while self.capture.isOpened() and cv2.waitKey(1) == -1:\n",
    "            read_successfully, main_frame = self.capture.read()\n",
    "\n",
    "            if read_successfully:\n",
    "                yield main_frame\n",
    "\n",
    "        self.capture.release()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.frame_gen()\n",
    "    \n",
    "def main():\n",
    "    data_path = \"data\"\n",
    "    video_name = \"cars-highway.mp4\"\n",
    "    video_path = os.path.join(data_path, video_name)\n",
    "\n",
    "    video = Video(video_path)\n",
    "    print(f\"{video.name = }\")\n",
    "    print(f\"{video.shape = }\")\n",
    "    print(f\"{video.fps = }\")\n",
    "\n",
    "    # Save processed video into a file\n",
    "    size = (video.shape[0], video.shape[1]) \n",
    "   \n",
    "    data_path = \"data\"\n",
    "    output_name = \"processed-cars-highway.mp4\"\n",
    "    output_path = os.path.join(data_path, output_name)\n",
    "\n",
    "    result = cv2.VideoWriter(output_path, -1, video.fps, size) \n",
    "\n",
    "    models_path = \"pretrained_models\"\n",
    "    model_name = \"yolo11n.pt\"\n",
    "    yolo_path = os.path.join(models_path, model_name)\n",
    "\n",
    "    yolo = YOLO(yolo_path, verbose=False)\n",
    "\n",
    "    x1_roi, x2_roi = 90, 280\n",
    "    y1_roi, y2_roi = 170, 290\n",
    "    roi_mask = slice(y1_roi, y2_roi), slice(x1_roi, x2_roi)\n",
    "\n",
    "    obj_positions = {}\n",
    "    obj_velocities = {}\n",
    "    avg_velocities = {}\n",
    "    detection_lifetime_frames = 5\n",
    "\n",
    "    for i, frame in enumerate(video):\n",
    "        results = yolo.track(frame[roi_mask], persist=True, classes=[2, 7], conf=0.45, iou=0.5, verbose=False)\n",
    "\n",
    "        for obj in results[0].boxes:\n",
    "            try:\n",
    "                id = int(obj.id.item())\n",
    "                x, y, *_ = map(int, obj.xywh[0].numpy())\n",
    "                obj_pos_frame = (x, y, i)\n",
    "\n",
    "                if id not in obj_positions.keys():\n",
    "                    obj_positions[id] = [obj_pos_frame]\n",
    "                    obj_velocities[id] = [None]\n",
    "                    avg_velocities[id] = None\n",
    "                else:\n",
    "                    obj_positions[id].append(obj_pos_frame)\n",
    "                    xpx_diff = obj_positions[id][-1][0] - obj_positions[id][-2][0] # Omitted for simplicity\n",
    "                    ypx_diff = obj_positions[id][-1][1] - obj_positions[id][-2][1]\n",
    "                    frame_diff = obj_positions[id][-1][2] - obj_positions[id][-2][2]\n",
    "\n",
    "                    vx = xpx_diff/frame_diff * video.fps # Omitted for simplicity\n",
    "                    vy = -ypx_diff/frame_diff * video.fps\n",
    "\n",
    "                    if obj_velocities[id] == [None]:\n",
    "                        obj_velocities[id] = [vy]\n",
    "                        avg_velocities[id] = vy\n",
    "                    else:\n",
    "                        obj_velocities[id].append(vy)\n",
    "                        avg_velocities[id] = np.mean(obj_velocities[id])\n",
    "                        cv2.putText(frame[roi_mask], f\"{avg_velocities[id]:.2f} px/s\", (x, y+7), 0, 0.5, (0, 255, 0), 1)\n",
    "            \n",
    "\n",
    "                cv2.circle(frame[roi_mask], (x, y), 3, (0, 0, 255), -1)\n",
    "\n",
    "            except AttributeError:\n",
    "                print(\"Invalid object, resuming...\")\n",
    "                continue\n",
    "\n",
    "        cv2.rectangle(frame, (x1_roi, y1_roi), (x2_roi, y2_roi), (0, 0, 255), 2)\n",
    "\n",
    "        vehicle_count = len(results[0].boxes)\n",
    "        cv2.putText(frame, f\"Vehicle count: {vehicle_count}\", (x2_roi+5, y1_roi-5), 0, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        filtered = [value for value in avg_velocities.values() if value is not None] # Remove None's\n",
    "        if filtered:\n",
    "            avg_speed = np.mean(filtered)\n",
    "            bool_traffic = avg_speed < 15 and vehicle_count > 3\n",
    "            cv2.putText(frame, f\"Traffic: {bool_traffic}\", (20, 20), 0, 0.5, (255, 0, 0), 1)\n",
    "            cv2.putText(frame, f\"Avg speed: {avg_speed:.2f}px/s\", (x1_roi-5, y1_roi-5), 0, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow(\"YOLO\", frame)\n",
    "        result.write(frame)\n",
    "\n",
    "        for id in list(obj_positions.keys()):\n",
    "            if i - obj_positions[id][-1][-1] > detection_lifetime_frames:\n",
    "                del obj_positions[id]\n",
    "                del obj_velocities[id]\n",
    "                del avg_velocities[id]\n",
    "    \n",
    "    result.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: pretrained_models\\yolo11n.pt\n",
      "Labels(n=80): ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "models_path = \"pretrained_models\"\n",
    "filename = \"yolo11n.pt\"\n",
    "input_path = os.path.join(models_path, filename)\n",
    "\n",
    "model = YOLO(input_path)\n",
    "labels = list(model.names.values())\n",
    "n = len(labels)\n",
    "\n",
    "print(f\"Model: {input_path}\")\n",
    "print(f\"Labels({n=}): {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 persons, 1 bus, 175.8ms\n",
      "Speed: 6.0ms preprocess, 175.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([5.])\n",
      "conf: tensor([0.9402])\n",
      "data: tensor([[  3.8328, 229.3642, 796.1946, 728.4123,   1.0000,   0.9402,   5.0000]])\n",
      "id: tensor([1.])\n",
      "is_track: True\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([1, 7])\n",
      "xywh: tensor([[400.0137, 478.8882, 792.3618, 499.0481]])\n",
      "xywhn: tensor([[0.4938, 0.4434, 0.9782, 0.4621]])\n",
      "xyxy: tensor([[  3.8328, 229.3642, 796.1946, 728.4123]])\n",
      "xyxyn: tensor([[0.0047, 0.2124, 0.9830, 0.6745]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "data_path = \"data\"\n",
    "filename = \"bus.jpg\"\n",
    "input_path = os.path.join(data_path, filename)\n",
    "\n",
    "frame = cv2.imread(input_path)\n",
    "try:\n",
    "    results = model.track(frame, show=True)\n",
    "\n",
    "    obj_1 = results[0].boxes[0]\n",
    "    print(obj_1)\n",
    "finally:\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 640x480 4 persons, 1 bus, 184.4ms\n",
      "Speed: 9.0ms preprocess, 184.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "Label(id=5): bus\n",
      "-> Location: x=400.01, y=478.89, w=792.36, h=499.05\n",
      "\n",
      "Label(id=0): person\n",
      "-> Location: x=740.41, y=636.77, w=138.79, h=483.88\n",
      "\n",
      "Label(id=0): person\n",
      "-> Location: x=143.35, y=651.88, w=191.90, h=504.63\n",
      "\n",
      "Label(id=0): person\n",
      "-> Location: x=283.76, y=634.56, w=121.41, h=451.75\n",
      "\n",
      "Label(id=0): person\n",
      "-> Location: x=34.45, y=714.21, w=68.86, h=316.29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "data_path = \"data\"\n",
    "filename = \"bus.jpg\"\n",
    "input_path = os.path.join(data_path, filename)\n",
    "\n",
    "frame = cv2.imread(input_path)\n",
    "try:\n",
    "    results = model.track(frame, show=True)\n",
    "    print()\n",
    "    for obj in results[0].boxes:\n",
    "        id = obj.cls.item() # .item() extracts value of tensor of a single element\n",
    "        x, y, w, h = obj.xywh[0].numpy() # converting to numpy allows to unpack (readability)\n",
    "        print(f\"Label(id={id:.0f}): {model.names[id]}\", end=\"\\n-> \")\n",
    "        print(f\"Location: {x=:.2f}, {y=:.2f}, {w=:.2f}, {h=:.2f}\", end=\"\\n\\n\")\n",
    "finally:\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
